{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6ff40-26e8-48d5-aac4-f0b9c18af798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from requests import get\n",
    "import pickle\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10509ef8-57f0-4e1c-b771-2afbefdac338",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "        \"pgf.texsystem\": \"pdflatex\",\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": \"Helvetica\",\n",
    "        'pgf.rcfonts': False,\n",
    "    })\n",
    "\n",
    "plt.style.use('seaborn-v0_8-ticks')\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',\n",
    "                        '#9467bd', '#8c564b', '#e377c2', '#7f7f7f',\n",
    "                        '#bcbd22', '#17becf']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048e937f",
   "metadata": {},
   "source": [
    "# Load learning dynamics data of primed and unprimed model\n",
    "\n",
    "One can also use this to load the learning dynamics of the finetuned model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16defa8-3091-4a54-91d0-e7f0aa3521ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2 # Number of layers\n",
    "s = 0.3 # Train/test split\n",
    "w = 0.2 # weight decay\n",
    "\n",
    "### Unprimed model\n",
    "\n",
    "p = 0\n",
    "\n",
    "directory = 'unprimed/'.format(n, s, w)\n",
    "\n",
    "Data_out = []\n",
    "\n",
    "inputFile = 'DATA_n{!s}_s{!s}_w{!s}_{!s}_epoch_1000.data'.format(n, s, w, p)\n",
    "inputFile = directory + inputFile\n",
    "fd = open(inputFile, 'rb')\n",
    "Data_out.append(pickle.load(fd))\n",
    "\n",
    "### Primed model\n",
    "\n",
    "p = 0\n",
    "\n",
    "directory = 'primed/'.format(n, s, w)\n",
    "\n",
    "inputFile = 'DATA_n{!s}_s{!s}_w{!s}_{!s}.data'.format(n, s, w, p)\n",
    "inputFile = directory + inputFile\n",
    "fd = open(inputFile, 'rb')\n",
    "Data_out.append(pickle.load(fd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f96492",
   "metadata": {},
   "source": [
    "# To reproduce Fig. 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ff3aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1000\n",
    "\n",
    "fig, ax = plt.subplots(1, 6, figsize=(25, 4))\n",
    "fig.tight_layout(w_pad=2)\n",
    "\n",
    "for i, data in enumerate(Data_out):\n",
    "\n",
    "    token = torch.stack(data[-2])\n",
    "\n",
    "    colors = ['#1f77b4', '#ff7f0e']\n",
    "\n",
    "    for k in range(6):\n",
    "            \n",
    "        ax[k].plot(token[:, k], color = colors[i])\n",
    "        # ax[k].plot(token[:, k].mean(0), color = 'black')\n",
    "\n",
    "        ax[k].set_xlabel('Epochs')\n",
    "        ax[k].set_ylabel('Accuracy')\n",
    "\n",
    "lg = fig.legend(['no priming', 'priming'], bbox_to_anchor=(1.07, 0.4), loc='lower right', borderaxespad=0.)\n",
    "for handle in lg.legend_handles:\n",
    "    handle.set_alpha(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4188f393c34fa2b8c99d7feb044de464e631de5d42645b8d328d986184b8407"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
